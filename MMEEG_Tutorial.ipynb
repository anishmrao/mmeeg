{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "851f998f",
   "metadata": {},
   "source": [
    "# MMEEG Tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e7fb737",
   "metadata": {},
   "source": [
    "This tutorial shows how to use this repository to train your model. You can implement your model and register it in the models registry, similar to the current models - EEGConformer and EEGNet. The rest of the steps are the same. This allows for easy abstraction of training code and quick, config-driven experimentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d83d5b5",
   "metadata": {},
   "source": [
    "Start off by importing the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88cd96c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msai/anishmad001/.conda/envs/mmcls/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mmengine.evaluator import BaseMetric\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.config import Config\n",
    "\n",
    "from models.registry import MODELS\n",
    "from datasets.registry import DATASETS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fdd7c3a",
   "metadata": {},
   "source": [
    "Next, select the config for the model you wish to train. See the configs folder for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aaa18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First blocks out shape: torch.Size([1, 16, 1, 15])\n"
     ]
    }
   ],
   "source": [
    "# cfg = Config.fromfile('configs/eeg_conformer_config.py')\n",
    "cfg = Config.fromfile('configs/eegnet_config.py')\n",
    "model = MODELS.build(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae9d7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMEEGNet(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (model): eegNet(\n",
       "    (firstBlocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 8, kernel_size=(1, 125), stride=(1, 1), padding=(0, 62), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2dWithConstraint(8, 16, kernel_size=(64, 1), stride=(1, 1), groups=8, bias=False)\n",
       "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ELU(alpha=1.0)\n",
       "        (5): AvgPool2d(kernel_size=(1, 4), stride=4, padding=0)\n",
       "        (6): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(1, 22), stride=(1, 1), padding=(0, 11), groups=16, bias=False)\n",
       "        (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): AvgPool2d(kernel_size=(1, 8), stride=8, padding=0)\n",
       "        (5): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (lastLayer): Sequential(\n",
       "      (0): Conv2d(16, 4, kernel_size=(1, 15), stride=(1, 1))\n",
       "      (1): LogSoftmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fd5ed52",
   "metadata": {},
   "source": [
    "You can also define custom metrics for your experiment if required. Below is an example implementation of the Accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ceab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(BaseMetric):\n",
    "    def process(self, data_batch, data_samples):\n",
    "        score, gt = data_samples\n",
    "        self.results.append({\n",
    "            'batch_size': len(gt),\n",
    "            'correct': (score.argmax(dim=1) == gt).sum().cpu(),\n",
    "        })\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        total_correct = sum(item['correct'] for item in results)\n",
    "        total_size = sum(item['batch_size'] for item in results)\n",
    "        return dict(accuracy=100 * total_correct / total_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb53868d",
   "metadata": {},
   "source": [
    "The standard EEGDataset is provided with the repository and need not be reimplemented if your dataformat is the same. However, you can implement your own Dataset class and register it with the DATASETS registry to use it like below to build your training, validation and testing datasets. Please see the implementation of the EEGDataset under the datasets folder for an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc4fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DATASETS.build(cfg.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a5e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DATASETS.build(cfg.val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c7af801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 480])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27973bcf",
   "metadata": {},
   "source": [
    "Create a dataloder next, which will be used by the mmengine runner. I'm using the default torch.utils.data Dataloader here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "433d09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(batch_size=32,\n",
    "                              shuffle=True,\n",
    "                              dataset=dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bddddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(batch_size=32,\n",
    "                            shuffle=False,\n",
    "                            dataset=val_dataset)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4cd76e1",
   "metadata": {},
   "source": [
    "And that's it! We're ready to train the model. You can set the optimizer to be used, the number of epochs, how often to perform validation, etc. More options for the mmengine runner can be found in their official [documentation](https://mmengine.readthedocs.io/en/latest/tutorials/runner.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1c9a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/03 02:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 332588215\n",
      "    GPU 0: NVIDIA A40\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (GCC) 11.2.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.6.0\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: None\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "04/03 02:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "\n",
      "\n",
      "04/03 02:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "04/03 02:40:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "04/03 02:40:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/msai/anishmad001/codes/mmeeg/work_dir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msai/anishmad001/.conda/envs/mmcls/lib/python3.10/site-packages/mmengine-0.6.0-py3.10.egg/mmengine/runner/loops.py:56: UserWarning: Dataset EEGDataset has no metainfo. ``dataset_meta`` in visualizer will be None.\n",
      "  warnings.warn(\n",
      "/home/msai/anishmad001/.conda/envs/mmcls/lib/python3.10/site-packages/mmengine-0.6.0-py3.10.egg/mmengine/evaluator/metric.py:47: UserWarning: The prefix is not set in metric class Accuracy.\n",
      "  warnings.warn('The prefix is not set in metric class '\n",
      "/home/msai/anishmad001/.conda/envs/mmcls/lib/python3.10/site-packages/mmengine-0.6.0-py3.10.egg/mmengine/runner/loops.py:335: UserWarning: Dataset EEGDataset has no metainfo. ``dataset_meta`` in evaluator, metric and visualizer will be None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "04/03 02:40:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][8/8]  accuracy: 22.4900\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "04/03 02:40:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][8/8]  accuracy: 24.4980\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "04/03 02:40:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][8/8]  accuracy: 26.9076\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "04/03 02:40:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][8/8]  accuracy: 32.1285\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "04/03 02:40:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][8/8]  accuracy: 35.7430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MMEEGNet(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (model): eegNet(\n",
       "    (firstBlocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 8, kernel_size=(1, 125), stride=(1, 1), padding=(0, 62), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2dWithConstraint(8, 16, kernel_size=(64, 1), stride=(1, 1), groups=8, bias=False)\n",
       "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ELU(alpha=1.0)\n",
       "        (5): AvgPool2d(kernel_size=(1, 4), stride=4, padding=0)\n",
       "        (6): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(1, 22), stride=(1, 1), padding=(0, 11), groups=16, bias=False)\n",
       "        (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): AvgPool2d(kernel_size=(1, 8), stride=8, padding=0)\n",
       "        (5): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (lastLayer): Sequential(\n",
       "      (0): Conv2d(16, 4, kernel_size=(1, 15), stride=(1, 1))\n",
       "      (1): LogSoftmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = Runner(\n",
    "    model=model,\n",
    "    work_dir='./work_dir',\n",
    "    train_dataloader=train_dataloader,\n",
    "    optim_wrapper=dict(optimizer=dict(type=SGD, lr=0.001, momentum=0.9)),\n",
    "    train_cfg=dict(by_epoch=True, max_epochs=5, val_interval=1),\n",
    "    val_dataloader=val_dataloader,\n",
    "    val_cfg=dict(),\n",
    "    val_evaluator=dict(type=Accuracy),\n",
    ")\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
