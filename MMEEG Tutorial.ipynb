{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88cd96c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msai/anishmad001/.conda/envs/mmcls/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mmengine.evaluator import BaseMetric\n",
    "from mmengine.model import BaseModel\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.config import Config\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import datetime\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import scipy.io\n",
    "# import argparse\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# cfg = Config.fromfile('models/eeg_conformer_config.py')\n",
    "from models.registry import MODELS\n",
    "from datasets.registry import DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f27c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PatchEmbedding(nn.Module):\n",
    "#     def __init__(self, emb_size=40):\n",
    "#         # self.patch_size = patch_size\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.shallownet = nn.Sequential(\n",
    "#             nn.Conv2d(1, 40, (1, 15), (1, 1)),\n",
    "#             nn.Conv2d(40, 40, (64, 1), (1, 1)),\n",
    "#             nn.BatchNorm2d(40),\n",
    "#             nn.ELU(),\n",
    "#             nn.AvgPool2d((1, 75), (1, 15)),  # pooling acts as slicing to obtain 'patch' along the time dimension as in ViT\n",
    "#             nn.Dropout(0.5),\n",
    "#         )\n",
    "\n",
    "#         self.projection = nn.Sequential(\n",
    "#             nn.Conv2d(40, emb_size, (1, 1), stride=(1, 1)),  # transpose, conv could enhance fiting ability slightly\n",
    "#             Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "#         )\n",
    "\n",
    "\n",
    "#     def forward(self, x: Tensor) -> Tensor:\n",
    "#         b, _, _, _ = x.shape\n",
    "#         x = self.shallownet(x)\n",
    "#         x = self.projection(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, emb_size, num_heads, dropout):\n",
    "#         super().__init__()\n",
    "#         self.emb_size = emb_size\n",
    "#         self.num_heads = num_heads\n",
    "#         self.keys = nn.Linear(emb_size, emb_size)\n",
    "#         self.queries = nn.Linear(emb_size, emb_size)\n",
    "#         self.values = nn.Linear(emb_size, emb_size)\n",
    "#         self.att_drop = nn.Dropout(dropout)\n",
    "#         self.projection = nn.Linear(emb_size, emb_size)\n",
    "\n",
    "#     def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
    "#         queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
    "#         keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
    "#         values = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
    "#         energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)  \n",
    "#         if mask is not None:\n",
    "#             fill_value = torch.finfo(torch.float32).min\n",
    "#             energy.mask_fill(~mask, fill_value)\n",
    "\n",
    "#         scaling = self.emb_size ** (1 / 2)\n",
    "#         att = F.softmax(energy / scaling, dim=-1)\n",
    "#         att = self.att_drop(att)\n",
    "#         out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
    "#         out = rearrange(out, \"b h n d -> b n (h d)\")\n",
    "#         out = self.projection(out)\n",
    "#         return out\n",
    "\n",
    "\n",
    "# class ResidualAdd(nn.Module):\n",
    "#     def __init__(self, fn):\n",
    "#         super().__init__()\n",
    "#         self.fn = fn\n",
    "\n",
    "#     def forward(self, x, **kwargs):\n",
    "#         res = x\n",
    "#         x = self.fn(x, **kwargs)\n",
    "#         x += res\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class FeedForwardBlock(nn.Sequential):\n",
    "#     def __init__(self, emb_size, expansion, drop_p):\n",
    "#         super().__init__(\n",
    "#             nn.Linear(emb_size, expansion * emb_size),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(drop_p),\n",
    "#             nn.Linear(expansion * emb_size, emb_size),\n",
    "#         )\n",
    "\n",
    "\n",
    "# class GELU(nn.Module):\n",
    "#     def forward(self, input: Tensor) -> Tensor:\n",
    "#         return input*0.5*(1.0+torch.erf(input/math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "# class TransformerEncoderBlock(nn.Sequential):\n",
    "#     def __init__(self,\n",
    "#                  emb_size,\n",
    "#                  num_heads=10,\n",
    "#                  drop_p=0.5,\n",
    "#                  forward_expansion=4,\n",
    "#                  forward_drop_p=0.5):\n",
    "#         super().__init__(\n",
    "#             ResidualAdd(nn.Sequential(\n",
    "#                 nn.LayerNorm(emb_size),\n",
    "#                 MultiHeadAttention(emb_size, num_heads, drop_p),\n",
    "#                 nn.Dropout(drop_p)\n",
    "#             )),\n",
    "#             ResidualAdd(nn.Sequential(\n",
    "#                 nn.LayerNorm(emb_size),\n",
    "#                 FeedForwardBlock(\n",
    "#                     emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
    "#                 nn.Dropout(drop_p)\n",
    "#             )\n",
    "#             ))\n",
    "\n",
    "\n",
    "# class TransformerEncoder(nn.Sequential):\n",
    "#     def __init__(self, depth, emb_size):\n",
    "#         super().__init__(*[TransformerEncoderBlock(emb_size) for _ in range(depth)])\n",
    "\n",
    "\n",
    "# class ClassificationHead(nn.Sequential):\n",
    "#     def __init__(self, emb_size, n_classes):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         # global average pooling\n",
    "#         self.clshead = nn.Sequential(\n",
    "#             Reduce('b n e -> b e', reduction='mean'),\n",
    "#             nn.LayerNorm(emb_size),\n",
    "#             nn.Linear(emb_size, n_classes)\n",
    "#         )\n",
    "#         self.fc = nn.Sequential(\n",
    "#             # nn.Linear(44720, 2440),\n",
    "#             # nn.ELU(),\n",
    "#             nn.Linear(1080, 256),\n",
    "#             nn.ELU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(256, 32),\n",
    "#             nn.ELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(32, 4)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.contiguous().view(x.size(0), -1)\n",
    "#         out = self.fc(x)\n",
    "#         return x, out\n",
    "\n",
    "\n",
    "# class Conformer(nn.Sequential):\n",
    "#     def __init__(self, emb_size=40, depth=6, n_classes=4, **kwargs):\n",
    "#         super().__init__(\n",
    "\n",
    "#             PatchEmbedding(emb_size),\n",
    "#             TransformerEncoder(depth, emb_size),\n",
    "#             ClassificationHead(emb_size, n_classes)\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0850789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @MODELS.register_module()\n",
    "# class MMEEGConformer(BaseModel):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.model = Conformer()\n",
    "\n",
    "#     def forward(self, trials, labels, mode):\n",
    "#         Tok, Cls = self.model(trials)\n",
    "#         if mode == 'loss':\n",
    "#             return {'loss': F.cross_entropy(Cls, labels)}\n",
    "#         elif mode == 'predict':\n",
    "#             return Cls, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aaa18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First blocks out shape: torch.Size([1, 16, 1, 15])\n"
     ]
    }
   ],
   "source": [
    "# cfg = Config.fromfile('configs/eeg_conformer_config.py')\n",
    "cfg = Config.fromfile('configs/eegnet_config.py')\n",
    "model = MODELS.build(cfg.model)\n",
    "# model = MODELS.build(dict(type='MMEEGConformer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae9d7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMEEGNet(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (model): eegNet(\n",
       "    (firstBlocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 8, kernel_size=(1, 125), stride=(1, 1), padding=(0, 62), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2dWithConstraint(8, 16, kernel_size=(64, 1), stride=(1, 1), groups=8, bias=False)\n",
       "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ELU(alpha=1.0)\n",
       "        (5): AvgPool2d(kernel_size=(1, 4), stride=4, padding=0)\n",
       "        (6): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(1, 22), stride=(1, 1), padding=(0, 11), groups=16, bias=False)\n",
       "        (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): AvgPool2d(kernel_size=(1, 8), stride=8, padding=0)\n",
       "        (5): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (lastLayer): Sequential(\n",
       "      (0): Conv2d(16, 4, kernel_size=(1, 15), stride=(1, 1))\n",
       "      (1): LogSoftmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f13c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, (22, 288, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ceab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(BaseMetric):\n",
    "    def process(self, data_batch, data_samples):\n",
    "        score, gt = data_samples\n",
    "        self.results.append({\n",
    "            'batch_size': len(gt),\n",
    "            'correct': (score.argmax(dim=1) == gt).sum().cpu(),\n",
    "        })\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        total_correct = sum(item['correct'] for item in results)\n",
    "        total_size = sum(item['batch_size'] for item in results)\n",
    "        return dict(accuracy=100 * total_correct / total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc64ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EEGDataset(Dataset):\n",
    "#     def __init__(self, data_root, subs, batch_size, augment=True):\n",
    "#         self.root = data_root\n",
    "#         self.subs = subs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.augment = augment\n",
    "#         self.allData=None\n",
    "#         self.allLabel=None\n",
    "#         self.create_dataset()\n",
    "    \n",
    "#     def get_source_data(self, sub):\n",
    "#         total_data = scipy.io.loadmat(os.path.join(self.root, '%d.mat' % sub))\n",
    "#         train_data = total_data['data']\n",
    "#         train_label = total_data['label']\n",
    "\n",
    "#         train_data = np.transpose(train_data, (2, 1, 0))\n",
    "#         train_data = np.expand_dims(train_data, axis=1)\n",
    "#         train_label = np.transpose(train_label)\n",
    "\n",
    "#         allData = train_data\n",
    "#         allLabel = train_label[0]\n",
    "\n",
    "#         shuffle_num = np.random.permutation(len(allData))\n",
    "#         allData = allData[shuffle_num, :, :, :]\n",
    "#         allLabel = allLabel[shuffle_num]\n",
    "\n",
    "#         # standardize\n",
    "#         target_mean = np.mean(allData)\n",
    "#         target_std = np.std(allData)\n",
    "#         allData = (allData - target_mean) / target_std\n",
    "\n",
    "#         # data shape: (trial, conv channel, electrode channel, time samples)\n",
    "#         return allData, allLabel\n",
    "\n",
    "#     def create_dataset(self):\n",
    "#         for sub in self.subs:\n",
    "#             allData, allLabel = self.get_source_data(sub)\n",
    "#             if(self.allData is None):\n",
    "#                 self.allData = allData\n",
    "#                 self.allLabel = allLabel\n",
    "#             else:\n",
    "#                 self.allData = np.concatenate((self.allData, allData), axis=0)\n",
    "#                 self.allLabel = np.concatenate((self.allLabel, allLabel), axis=0)\n",
    "        \n",
    "#         self.allData = torch.from_numpy(self.allData)\n",
    "#         self.allLabel = torch.from_numpy(self.allLabel)\n",
    "        \n",
    "#         if(self.augment):\n",
    "#             aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "#             self.allData = torch.cat((self.allData, aug_data))\n",
    "#             self.allLabel = torch.cat((self.allLabel, aug_label))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.allData)\n",
    "    \n",
    "#     def interaug(self, timg, label):  \n",
    "#         aug_data = []\n",
    "#         aug_label = []\n",
    "#         for cls4aug in range(4):\n",
    "#             cls_idx = np.where(label == cls4aug)\n",
    "#             tmp_data = timg[cls_idx]\n",
    "#             tmp_label = label[cls_idx]\n",
    "\n",
    "#             tmp_aug_data = np.zeros((int(self.batch_size / 4), 1, 64, 480))\n",
    "#             for ri in range(int(self.batch_size / 4)):\n",
    "#                 for rj in range(8):\n",
    "#                     rand_idx = np.random.randint(0, tmp_data.shape[0], 8)\n",
    "#                     tmp_aug_data[ri, :, :, rj * 60:(rj + 1) * 60] = tmp_data[rand_idx[rj], :, :,\n",
    "#                                                                       rj * 60:(rj + 1) * 60]\n",
    "\n",
    "#             aug_data.append(tmp_aug_data)\n",
    "#             aug_label.append(tmp_label[:int(self.batch_size / 4)])\n",
    "        \n",
    "#         aug_data = np.concatenate(aug_data)\n",
    "#         aug_label = np.concatenate(aug_label)\n",
    "#         aug_shuffle = np.random.permutation(len(aug_data))\n",
    "#         aug_data = aug_data[aug_shuffle, :, :]\n",
    "#         aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "#         aug_data = torch.from_numpy(aug_data)\n",
    "#         aug_data = aug_data.float()\n",
    "#         aug_label = torch.from_numpy(aug_label)\n",
    "#         aug_label = aug_label.long()\n",
    "#         return aug_data, aug_label\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.allData[idx].type(torch.FloatTensor), self.allLabel[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b603043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '/home/msai/anishmad001/codes/EEG-Conformer/data/phisionet'\n",
    "# TRAIN_SUBS = [1,2,3]\n",
    "# VAL_SUBS = [4,5,6]\n",
    "# BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc4fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DATASETS.build(cfg.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a5e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DATASETS.build(cfg.val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "556edf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.eeg_dataset.EEGDataset at 0x155497332c80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775a3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = EEGDataset(data_root=DATA_PATH, subs=TRAIN_SUBS, batch_size=BATCH_SIZE, augment=False)\n",
    "\n",
    "# val_dataset = EEGDataset(data_root=DATA_PATH, subs=VAL_SUBS, batch_size=BATCH_SIZE, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c7af801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 480])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "433d09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(batch_size=32,\n",
    "                              shuffle=True,\n",
    "                              dataset=dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bddddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(batch_size=32,\n",
    "                            shuffle=False,\n",
    "                            dataset=val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1c9a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/03 02:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 332588215\n",
      "    GPU 0: NVIDIA A40\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (GCC) 11.2.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.6.0\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: None\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "04/03 02:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "\n",
      "\n",
      "04/03 02:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "04/03 02:40:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "04/03 02:40:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/msai/anishmad001/codes/mmeeg/work_dir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msai/anishmad001/.conda/envs/mmcls/lib/python3.10/site-packages/mmengine-0.6.0-py3.10.egg/mmengine/runner/loops.py:56: UserWarning: Dataset EEGDataset has no metainfo. ``dataset_meta`` in visualizer will be None.\n",
      "  warnings.warn(\n",
      "/home/msai/anishmad001/.conda/envs/mmcls/lib/python3.10/site-packages/mmengine-0.6.0-py3.10.egg/mmengine/evaluator/metric.py:47: UserWarning: The prefix is not set in metric class Accuracy.\n",
      "  warnings.warn('The prefix is not set in metric class '\n",
      "/home/msai/anishmad001/.conda/envs/mmcls/lib/python3.10/site-packages/mmengine-0.6.0-py3.10.egg/mmengine/runner/loops.py:335: UserWarning: Dataset EEGDataset has no metainfo. ``dataset_meta`` in evaluator, metric and visualizer will be None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "04/03 02:40:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][8/8]  accuracy: 22.4900\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "04/03 02:40:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][8/8]  accuracy: 24.4980\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "04/03 02:40:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][8/8]  accuracy: 26.9076\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "04/03 02:40:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][8/8]  accuracy: 32.1285\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: 20230403_024031\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "04/03 02:40:35 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `save_param_scheduler` is True but `self.param_schedulers` is None, so skip saving parameter schedulers\n",
      "04/03 02:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][8/8]  accuracy: 35.7430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MMEEGNet(\n",
       "  (data_preprocessor): BaseDataPreprocessor()\n",
       "  (model): eegNet(\n",
       "    (firstBlocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 8, kernel_size=(1, 125), stride=(1, 1), padding=(0, 62), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2dWithConstraint(8, 16, kernel_size=(64, 1), stride=(1, 1), groups=8, bias=False)\n",
       "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ELU(alpha=1.0)\n",
       "        (5): AvgPool2d(kernel_size=(1, 4), stride=4, padding=0)\n",
       "        (6): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(1, 22), stride=(1, 1), padding=(0, 11), groups=16, bias=False)\n",
       "        (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): AvgPool2d(kernel_size=(1, 8), stride=8, padding=0)\n",
       "        (5): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (lastLayer): Sequential(\n",
       "      (0): Conv2d(16, 4, kernel_size=(1, 15), stride=(1, 1))\n",
       "      (1): LogSoftmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = Runner(\n",
    "    model=model,\n",
    "    work_dir='./work_dir',\n",
    "    train_dataloader=train_dataloader,\n",
    "    optim_wrapper=dict(optimizer=dict(type=SGD, lr=0.001, momentum=0.9)),\n",
    "    train_cfg=dict(by_epoch=True, max_epochs=5, val_interval=1),\n",
    "    val_dataloader=val_dataloader,\n",
    "    val_cfg=dict(),\n",
    "    val_evaluator=dict(type=Accuracy),\n",
    ")\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573d87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
